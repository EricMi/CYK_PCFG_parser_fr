{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Splitting corpus into train/dev/test sets...\n",
      "Corpus size: 3099\n",
      "Train set size: 2479\n",
      "Dev set size: 310\n",
      "Test set size: 310\n",
      ">>> Corpus split done in 0.411s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import codecs\n",
    "import random\n",
    "from time import time\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus.reader.bracket_parse import BracketParseCorpusReader\n",
    "\n",
    "CORPUS = os.path.join(\"corpus\", \"sequoia-corpus+fct.mrg_strict\")\n",
    "TB_TRAIN = os.path.join(\"corpus\", \"sequoia_train.tb\")\n",
    "TB_DEV = os.path.join(\"corpus\", \"sequoia_dev.tb\")\n",
    "TB_TEST = os.path.join(\"corpus\", \"sequoia_test.tb\")\n",
    "TXT_DEV = os.path.join(\"corpus\", \"sequoia_dev.txt\")\n",
    "TXT_TEST = os.path.join(\"corpus\", \"sequoia_test.txt\")\n",
    "\n",
    "t0 = time()\n",
    "print (\">>> Splitting corpus into train/dev/test sets...\")\n",
    "\n",
    "nt_funcl_re = re.compile(r\"(?<=\\()[A-Za-z_+^\\-]+\\-[^ ]+\")\n",
    "def remove_funcl(m):\n",
    "    return m.group().split('-')[0]\n",
    "\n",
    "f_in = codecs.open(CORPUS, 'r', 'UTF-8')\n",
    "data = f_in.read().splitlines()\n",
    "for i in range(len(data)):\n",
    "    data[i] = nt_funcl_re.sub(lambda x: remove_funcl(x), data[i])\n",
    "f_in.close()\n",
    "\n",
    "s_total = len(data)\n",
    "p_train = 0.8\n",
    "p_dev = 0.1\n",
    "p_test = 0.1\n",
    "\n",
    "random.seed(39)\n",
    "random.shuffle(data)\n",
    "\n",
    "corpus_train = data[:int(s_total * p_train)]\n",
    "f_train = codecs.open(TB_TRAIN, 'w', 'UTF-8')\n",
    "for s in corpus_train:\n",
    "    f_train.write(u\"{0}\\n\".format(s))\n",
    "f_train.close()\n",
    "\n",
    "corpus_dev = data[int(s_total * p_train) : int(s_total * (p_train + p_dev))]\n",
    "f_dev = codecs.open(TB_DEV, 'w', 'UTF-8')\n",
    "for s in corpus_dev:\n",
    "    f_dev.write(u\"{0}\\n\".format(s))\n",
    "f_dev.close()\n",
    "\n",
    "corpus_test = data[int(s_total * (p_train + p_dev)):]\n",
    "f_test = codecs.open(TB_TEST, 'w', 'UTF-8')\n",
    "for s in corpus_test:\n",
    "    f_test.write(u\"{0}\\n\".format(s))\n",
    "f_test.close()\n",
    "\n",
    "corpus_root = r\"./corpus/\"\n",
    "\n",
    "dev_file_pattern = r\".*_dev\\.tb\"\n",
    "ptb_dev = BracketParseCorpusReader(corpus_root, dev_file_pattern)\n",
    "trees = ptb_dev.parsed_sents()\n",
    "f_out = codecs.open(TXT_DEV, 'w', 'UTF-8')\n",
    "for tree in trees:\n",
    "    f_out.write(u\"{0}\\n\".format(u\" \".join(tree.leaves())))\n",
    "f_out.close()\n",
    "\n",
    "test_file_pattern = r\".*_test\\.tb\"\n",
    "ptb_test = BracketParseCorpusReader(corpus_root, test_file_pattern)\n",
    "trees = ptb_test.parsed_sents()\n",
    "f_out = codecs.open(TXT_TEST, 'w', 'UTF-8')\n",
    "for tree in trees:\n",
    "    f_out.write(u\"{0}\\n\".format(u\" \".join(tree.leaves())))\n",
    "f_out.close()\n",
    "\n",
    "print (\"Corpus size: %d\" % s_total)\n",
    "print (\"Train set size: %d\" % len(corpus_train))\n",
    "print (\"Dev set size: %d\" % len(corpus_dev))\n",
    "print (\"Test set size: %d\" % len(corpus_test))\n",
    "\n",
    "print (\">>> Corpus split done in %0.3fs.\\n\" % (time() - t0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
